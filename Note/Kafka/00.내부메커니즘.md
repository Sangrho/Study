## 내부 메커니즘
아래 세 가지 초점으로 살펴본다.
- 카프카 복제가 동작하는 방법
- 카프카가 프로듀서와 컨슈머의 요청을 처리하는 방법
- 카프카가 스토리지(예를 들어, 파일 형식이나 인덱스)를 처리하는 방법

### 클러스터 멤버십

내부적으로 주키퍼는 표준 파일 시스템의 디렉터리처럼 계층적인 트리 구조로 데이터를 저장하고 사용한다.
그리고 데이터를 저장하는 노드를 znode라고 하며, 각 znode의 이름 앞에는 / 를 붙이고 디렉터리처럼 경로를 사용해서 각 노드의 위치를 식별한다.
각 노드에는 상태와 구성 정보 및 위치 정보 등의 데이터만 저장되므로 크기가 작으며(1KB 미만), 모든 노드가 메모리에 저장되어 처리되므로 속도라 빠르다.
그리고 임시(ephemeral) 노드와 영구(persistent) 노드로 구분된다.
임시 노드는 노드를 생성한 클라이언트가 연결되어 있을 때만 존재하며,
연결이 끊어지면 자동으로 삭제된다. 반면 영구 노드는 클라이언트가 삭제하지 않는한 계속 보존된다.</br></br>
카프카에서도 주키퍼를 사용해서 클러스터 멤버인 브로커들의 메타데이터를 유지 관리한다.
예를 들어 아래와 같다</br>

    /kafka-main/brokers : 브로커 관련 정보 저장
    /kafka-main/brokers/ids : 브로커 ID 저장
    /kafka-main/topics : 토픽 정보가 저장
    /kafka-main/config : 토픽의 설정 정보가 저장
    /kafka-main/consumers : 컨슈머의 파티션 오프셋 정보를 저장(0.9 버전부터 __consumer_offsets topic 에 저장되도록 변경됨)

모든 카프카 브로커는 고유 식별자를 가지며, 이것은 브로커의 구성 파일에 설정되거나 자동으로 생성된다.
브로커 프로세스는 시작될 때마다 주키퍼의 /brokers/id 에 임시 노드로 자신의 ID를 등록한다.
만일 같은 ID 를 갖는 다른 브로커를 시작하려고 하면 같은 주키퍼 노드가 이미 있으므로 에러가 발생한다.</br></br>
그리고 브로커 구성에서 브로커가 추가 혹은 삭제되거나 주키퍼와 연결이 끊어지면, 해당 브로커가 시작될 때 생성되었던 임시노드는 자동으로 주키퍼에서 삭제되며,
브로커 내역을 모니터링하는 카프카 컴포넌트들이 알 수 있다.(주키퍼의 Watch 설정)</br></br>
브로커가 중단되면 해당 브로커의 주키퍼 노드는 삭제된다. 그러나 해당 브로커의 ID는 여전히 다른 데이터 구조에 존재한다. 

### 컨트롤러

컨트롤러는 카프카 브로커 중 하나이며, 일반 브로커의 기능에 추가하여 파티션 리더를 선출하는 책임을 갖는다. 
클러스터에서 시작하는 첫 번째 브로커가 컨트롤러가 되며, 이 브로커는 주키퍼의 임시 노드인 /controller를 생성한다.
그리고 다른 브로커들이 시자고딜 때도 /controller 노드를 생성하려고 시도한다.
그러나 '노드가 이미 존재한다' 는 예외를 받으므로,
이미 /controller 노드가 있고 클러스터에도 컨트롤러가 있다는 것을 '알게된다'.
그리고 모든 브로커들은 /controller 노드에 주키퍼의 Watch를 생성하므로 이 노드에 변경이 생기는 것을 알 수 있다.
이런 방법을 통해서 클러스터에는 항상 하나의 컨트롤러만 존재한다.</br></br>
컨트롤러 브로커가 중단되거나 주키퍼와의 연결이 끊어지면 임시 노드인 /controller가 삭제된다.
이때 해당 클러스터의 다른 브로커들이 주키퍼의 Watch를 통해 그 사실을 알게 되고 /controller 노드의 생성을 시도한다.
그리고 그 노드를 첫 번째로 생성한 브로커가 컨트롤러가 되며, 다른 브로커들은 이미 얘기한 대로 '노드가 이미 존재한다'는 예외를 받는다.
또한 모든 브로커가 새소 생성된 /controller 노드에 주키퍼의 Watch를 생성한다.
컨트롤러는 매번 새로 선출될 때마다 주키퍼로부터 새로운 컨트롤러 세대 번호를 받으며,
나머지 브로커들은 현재의 컨트롤러 세대 번호를 알게 된다.
따라서 변경 전의 컨트롤러와 혼동되지 않으며, 이전 세대 번호로 된 컨트롤러 메세지를 받으며 무시한다.</br></br>
관련 주키퍼 경로를 Watch하여 특정 브로커가 클러스터를 떠났다는 것을 컨트롤러가 인지하면, 그 브로커가 리더로 할당되었던 모든 파티션들에
새로운 리더가 필요하다는 것을 알게 된다. 그 다음에 컨트롤러는 새로운 리더를 필요로 하는 모든 파티션들을 점검하고 새로 리더가 될 브로커를 결정한다.(간단히 해당 파티션의 리플리카 리스트에서 그 다음 순서의 브로커로 결정함).
그리고 컨트롤러는 파티션들의 새로운 리더들과 팔로워들의 정보를 모든 브로커들에게 전송한다.</br></br>
새로 결정된 각 파티션의 리더는 프로듀서와 컨슈머의 요청 처리를 시작해야 한다는 것을 알고 있으며, 팔로워들은 새로운 리더의 메세지 복제를 시작해야 한다는 것을 안다.</br></br>
새 브로커가 클러스터에 추가되면 컨트롤러는 브로커 ID를 사용해서 그 브로커의 리플리카로 사용할 브로커가 있는지 확인한다. 만일 있으면 컨트롤러는 새 브로커와 기존 브로커 모두에게 변경 사항을 알리며, 새 브로커의 리플리카들은 기존 리더들의 메세지를 복제하기 시작한다.</br></br>

### 복제

복제는 카프카 아키텍처의 핵심이다. 각 서버 노드에 장애가 생길 때 카프카가 가용성과 내구성을 보장하는 방법이기 때문이다. </br></br>리플리카에는 아래와 같이 두 가지 형태가 있다.

    * 리더 리플리카
        각 파티션은 리더로 지정된 하나의 리플리카를 갖는다. 일관성을 보장하기 위해 모든 프로듀서와 컨슈머 클라이언트의 요청은 리더를 
        통해서 처리된다.
    
    * 팔로워 리플리카
        각 파티션의 리더를 제외한 나머지 리플리카를 팔로워라고 한다. 팔로워는 클라이언트요청을 서비스하지 않는다. 
        대신에 리더의 메세지를 복제하여 리더의 것과 동일하게 유지한다. 그리고 특정 파티션의 리더 리플리카가 중단되는 경우에는 
        팔로워 리플리카 중 하나가 해당 파티션의 새로운 리더로 선출된다.

리더는 팔로워 리플리카 중에 어느 것이 최신의 리더 메세지를 복제하고 있는지 알아야 한다.
팔로워들은 리더가 받는 모든 최신 메세지를 복제하려고 한다.
그러나 여러 가지 이유로 동기화에 실패할 수 있다. 예를 들어, 네트워크의 혼잡으로 인해 복제가 늦어지는 경우다.
또는 브로커가 중단되어 해당 브로커를 시작시킨 후 다시 복제를 시작할 수 있을 때까지 해당 브로커의 모든 리플리카들의 복제가 늦어지게 되는 경우다.</br></br>
리더와 동기화를 하기 위해 리플리카들은 리더에게 Fetch 요청을 전송한다. 이것은 컨슈머가 메세지를 읽기 위해 전송하는 것과 같은 타입의 요청이다.
그리고 그런 요청의 응답으로 리더는 리플리카들에게 메세지를 전송한다.
Fetch 요청에는 리플리카가 다음으로 받기 원하는 메세지의 오프셋이 포함되며, 항상 수신된 순서대로 처리된다.</br></br>
이와는 반대로, 최신 메세지를 계속 요청하는 팔로워 리플리카를 동기화 리플리카(in-sync replica, ISR) 라고 한다. 기존 리더가 중단되는 경우 동기화 리플리카만이 리더로 선출될 수 있다.</br></br>
동기화되지 않는다고 간주되기 전에, 팔로워가 비활성 상태가 될 수 있는 지연 시간은 **replica.lag.time.max.ms** 구성 매개변수로 제어할 수 있다.
이 지연시간은 리더를 선출하는 동안의 클라이언트 실행과 데이터 보존에 영향을 준다.</br></br>
현재 리더에 추가하여 각 파티션은 선호 리더를 갖는다. 이것은 토픽이 생성될 때 각 파티션의 리더였던 리플리카들을 말한다.
하나의 토픽은 여러 개의 파티션으로 구성될 수 있으며, 파티션들을 처음 생성할 때는 여러 브로커가 고르게 파티션을 할당받아 리더가 되므로
이것이 선호되는 리더들이다. 결론적으로, 선호 리더들이 클러스터의 모든 파티션 리더들일 때는 브로커 간의 파티션 배분이 고르게 된다. 기본적으로 카프카는 auto.leader,rebalance.enable=true 로 구성된다. 이 경우 선호 리더 리플리카가 현재 리더느 ㄴ아닐 경우 동기화 리플리카인지 확인한다. 그리고 리더를 선출할 때 선호 리더를 현재 리더로 선출한다.</br></br>

    * 선호 리더 찾기
        파티션의 리플리카 내역을 보면 현재의 선호 리더를 찾을 수 있다. 
        출력 내역의 첫 번째 리플리카가 항상 선호 리더이며, 이것은 어떤 리플리카가 현재 리더라도 마찬가지다. 
        또한 리플리카가 재지정 도구를 사용해서 다른 브로커로 리플리카가 현재 리더라도 마찬가지다. 
        또한 리플리카 재지정 도구를 사용해서 다른 브로커로 리플리카를 재지정했어도 그렇다. 
        만일 우리가 직접 리플리카를 재지정한다면 제일 먼저 지정하는 리플리카가 선호 리더라는 것을 기억하자. 
        이렇게 하면 같은 파티션의 리더가 여러 브로커로 중복으로 지정되는 것을 막을 수 있다.

### 요청 처리

카프카 브로커가 하는 일은 대부분 클라이언트와 파티션 리플리카 및 컨트롤러부터 파티션 리더에게 전송되는 요청을 처리하는 것이다.
카프카는 TCP로 전송되는 이진 프로토콜을 갖고 있다. 이 프로토콜은 요청의 형식을 규정하고 있으며,
또한 요청이 성공적으로 처리되거나 처리 중 에러가 발생할 때 브로커가 응답하는 방법도 나타낸다.
클라이언트는 항상 연결을 개시하고 요청을 전송하며, 브로커는 해당 요청을 처리하고 응답한다.
특정 클라이언트로부터 브로커에 전송된 모든 요청은 항상 수신된 순서로 처리된다. 
따라서 카프카가 메세지 큐처럼 동작할 수 있어서 저장되는 메세지의 순서가 보장된다.</br></br>
쓰기 요청과 읽기 요청은 모두 파티션의 리더 리플리카에게 전송되어야 한다. 만일 어떤 브로커가 특정 파티션의 쓰기 요청을 수신했는데 해당 파티션의 리더가 다른 브로커라면,
쓰기 요청을 전송한 클라이언트는 '파티션 리더가 아님'이라는 에러 응답을 받는다. 또한 특정 파티션의 리더를 갖고 있지 않은 브로커가 해당 파티션의 읽기 요청을 수신할 때도 같은 에러가 발생한다. 카프카의 클라이언트들이 쓰기와 읽기 요청을 할 때는 요청 관련 파티션의 리더를 포함하는 브로커에게 요청을 전송해야 한다.</br></br>
그렇다면 어디로 요청을 전송할지 클라이언트가 어떻게 알 수 있을까?</br>
카프카 클라이언트는 메타데이터 요청이라는 또 다른 요청 타입을 사용하는데, 이것은 클라이언트가 관심을 갖는 토픽 내역을 포함한다. 그리고 메타데이터 요청에 대한 서버 응답에는 토픽에 존재하는 파티션들, 각 파티션의 리플리카, 어떤 리플리카가 리더인지 등의 정보가 포함된다. 메타데이터 요청은 어떤 브로커에도 전송할 수 있다. 모든 브로커가 그런 정보를 포함하는 메타데이터 캐시를 갖고 있기 때문이다.</br></br>
대개 클라이언트는 그런 정보를 캐시에 보존한 후 각 파티션의 올바른 브로커에게 쓰기와 읽기 요청을 전송하는 데 사용한다. 또한 메타데이터 요청을 전송하여 가끔 그런 정보를 새로 교체해야 한다.(새로 교체하는 시간 간격은 **metadata.max.age.ms** 구성 매개변수로 제어한다). 그래야만 새로운 브로커가 추가되었을 때처럼 토픽 메타데이터가 변경된 것을 알 수 있기 때문이다. 또한 클라이언트는 자신의 요청 중 하나에서 '파티션 리더가 아님' 에러를 수신할 때도 해당 요청을 다시 전송하기 전에 메타데이터를 새로 교체한다. 왜냐하면 클라이언트가 낡은 정보를 사용하여 엉뚱한 브로커에게 요청을 전송한 것이기 때문이다.

#### 쓰기 요청

acks 구성 매개변수에는 메세지를 수신해야 하는 브로커의 수를 설정하며, 설정된 값의 브로커가 모두 메세지를 수신해야 쓰기 성공으로 간주한다. 프로듀서의 acks 매개변수는 다음 세 가지 중 하나로 설정할 수 있다.</br>

    ack = -1 , 리더만 메세지를 받으면 됨
    ack = all , 모든 동기화 리플리카가 메세지를 받아야 함
    ack = 0 , 아예 브로커의 수신 응답을 기다리지 않음

특정 파티션의 리더 리플리카를 포함하는 브로커가 해당 파티션의 쓰기 요청을 받으면 다음 사항의 검사를 시작한다.</br>

- 데이터를 전송한 사용자가 해당 토픽의 쓰기 권한을 갖고 있는가?
- 해당 요청에 지정된 acks 의 값이 적합한가?
- 만일 acks 가 all 로 설정되었다면 메세지를 안전하게 쓰는 데 충분한 동기화 리플리카들이 있는가?

그 다음에 브로커는 로컬 디스크에 새로 받은 메세지를 쓴다. 리눅스의 경우에는 일단 파일 시스템 캐시에 메세지를 쓰지만 언제 디스크에 쓰는지 알 수 없다. 카프카는 디스크에 데이터 쓰기를 기다리지 않으며, 메세지의 내구성 보장을 위해 복제에 의존한다.</br></br>
일단 파티션 리더에 메세지를 쓰면 브로커는 acks 구성 매개변수를 살펴본다. 만일 acks의 값이 0 또는 1이면 즉시 응답을 전송한다. 그렇지 않고 all이면 팔로워 리플리카들이 해당 메세지를 복제했는지 리더가 확인할 때까지 퍼거토리(purgatory)라고 하는 버퍼에 해당 요청을 저장한다.

#### 읽기 요청

브로커는 쓰기 요청을 처리하는 방법과 매우 유사하게 읽기 요청을 처리한다. 클라이언트는 읽기를 원하는 토픽과 파티션 및 오프셋에 있는 메세지들의 읽기 요청을 브로커에게 전송한다. 또한, 클라이언트는 각 파티션마다 브로커가 반환할 수 있는 데이터 크기를 제한할 수 있다. 클라이언트는 브로커가 전송한 응답을 저장하는 메모리를 할당해야 하므로 데이터 크기 제한이 중요하다. 크기를 제한하지 않으면 클라이언트의 메모리 부족을 초래할 만큼 큰 응답을 브로커가 전송할 수 있다.</br></br>
이미 앞에서 얘기했듯이, 각 요청은 파티션 리더에게 전송되어야 한다. 따라서 읽기 요청이 올바르게 전달되도록 클라이언트는 필수적인 메타데이터 요청을 한다. 리더는 요청을 바은 후 그것이 적합한지 제일 먼저 검사한다. 만일 너무 오래되어서 해당 파티션에서 이미 삭제된 메세지나 아직 존재하지 않는 오프셋을 클라이언트가 요청하면 브로커는 에러를 응답한다.</br></br>
그러나 오프셋이 존재하면, 클라이언트가 요청에 지정한 제한 크기까지의 메세지들을 브로커가 해당 파티션에서 읽은 후 클라이언트에게 전송한다. 카프카는 **제로카피 기법** 을 사용해서 클라이언트에게 메세지를 전송한다. 즉, 카프카는 파일의 메세지를 중간 버퍼 메모리에 쓰지 않고 곧바로 네트워크 채널로 전송한다는 의미다. 이것은 데이터를 클라이언트에게 전송하기 전에 로컬 캐시 메모리에 저장하는 대부분의 데이터베이스와 다르다. 제로카피 기법은 메모리로부터 데이터를 복사하고 버퍼를 관리하는 부담을 제거하므로 성능이 훨씬 더 향상된다.</br></br>

    * 제로카피란
  
브로커가 반환할 수 있는 데이터의 상한 크기를 설정하는 것과 더불어, 클라이언트는 반환 데이터의 하한 크기도 설정할 수 있다. 예를 들어, 하한 크기를 10KB로 설정하면 다음과 같이 브로커에게 알려주는 셈이다. "읽은 메세지가 적어도 10KB가 될 때만 전송해라". 이것은 트래픽이 그리 많지 않은 토픽으로부터 클라이언트가 메세지를 읽을 때 CPU와 네트워크 사용을 줄일 수 있는 좋은 방법이다. 즉, 반환되는 데이터가 거의 없는데도 수밀리초마다 클라이언트가 브로커에게 요청을 전송하는 대신, 클라이언트는 요청을 전송하고 브로커는 하한 크기만큼 데이터가 채워지기를 기다렸다가 전송한다. 그리고 그 다음에 클라이언트가 추가로 읽기 요청하면된다. 결국 전체적으로는 같은 양의 데이터를 읽는다. 그러나 클라이언트와 브로커 간에 데이터를 주고 받는 횟수가 훨씬 줄어들게 되므로 여러 면에서 부담이 줄어든다.</br></br>
물론 브로커가 충분한 데이터를 가질 때까지 클라이언트가 마냥 기다리는 것을 원하지는 않는다. 대신에 잠시 기다렸다가 바로 데이터를 받아서 처리하는 것이 좋다. 이때 클라이언트는 타임아웃을 지정하여 다음과 같이 브로커에게 알려줄 수 있다. "만일 x 밀리초 동안에도 데이터의 하한 크기가 채워지지 않으면 현재 읽어둔 것을 전송해라".</br></br>
파티션 리더에 존재하는 모든 데이터를 클라이언트가 읽을 수 있는 것은 아님을 알아두자. 대부분의 클라이언트는 모든 동기화 리플리카에 쓴 메세지들만 일긍ㄹ 수 있다. 이미 배웠듯이, 파티션 리더는 어떤 메세지들이 어느 리플리카에 복제되었는지 안다. 그리고 모든 동기화 리플리카들이 메세지를 쓸 때까지는 컨슈머에게 전송되지 않는다.</br></br>
이렇게 하는 이유는 다음과 같다. 즉, 리플리카들에게 아직 복제되지 않는 메세지들은 '불안전한' 것으로 간주하기 때문이다. 만일 리더가 중단되어 다른 리플리카가 리더로 선출되면, 모든 리플리카에 복제되지 않은 메세지들은 더 이상 카프카에 존재하지 않게 된다. 또한 리더에만 존재하는 메세지들을 클라이언트가 읽을 수 있게 한다면, 일관성이 결여될 수 있다. 예를 들어, 어떤 컨슈머가 아직 복제되지 않은 메세지를 읽은 후 리더가 중단되면, 해당 메세지를 갖는 다른 브로커가 없으므로 그 메세지는 사라지게 된다. 그리고 다른 컨슈머들도 그 메세지를 읽을 수 없게 되어 그 메세지를 읽었던 컨슈머와의 일관성이 결여된다. 따라서 모든 동기화 리플리카가 해당 메세지를 복제할 때까지 기다렸다가 복제된 다음에 컨슈머가 읽을 수 있게 하는것이다. 그러나 브로커 간의 메세지 복제가 어떤 이유로든 느리게 수행된다면 복제가 끝날 때까지 기다려야 하므로 컨슈머들의 메세지를 읽는 시간도 더 오래 걸릴 것이다. 이런 지연 시간은 **replica.lag.time.max.ms** 매개 변수로 제한할 수 있다. 이 매개변수에는 리플리카가 살아 있는 것으로 간주되는 동안 새로운 메세지의 복제에 소요될 수 있는 제한 시간을 설정한다.

#### 기타 요청


### 스토리지

#### 파티션 할당

#### 파일 관리
#### 파일 형식

#### 인덱스

#### 압축

#### 압축 처리 방법

#### 삭제된 메세지

#### 토픽은 언제 압축될까?


Referenced from Kafka The definitive guide
