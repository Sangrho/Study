### Broker

* broker.id</br>
기본값은 0. 정수로 된 번호여야 하며, 고유해야 한다.

* port</br>
기본값은 9092. 어떤 포트 번호로도 설정할 수 있지만, 1024보다 작은 값으로 설정할 경우 카프카를 root 권한으로 수행해야 한다.

* zookeeper.connect</br>
기본값은 localhost:2181. 브로커의 메타데이터를 저장하기 위해 사용하는 주키퍼의 위치를 말한다.

* log.dirs</br>
로그 세그먼트를 저장하는 위치이다. log 라고 해서 카프카의 log가 아니다.

* num.recovery.threads.per.data.dir</br>
카프카는 구성 가능한 스레드 풀을 사용해서 로그세그먼트를 처리한다. 병행 실행이 가능한 코드인 스레드의 생성은 시간과 메모리가 필요하다.</br>
따라서 스레드의 개수를 제한하여 생성한 후 번갈아 사용하면 효율적이다. 이런 방법이 스레드 풀이다.</br>
스레드 풀은 다음의 경우 사용 된다.</br>

- 브로커가 정상적으로 시작될 때는 각 파티션의 로그 세그먼트 파일을 열기 위해 사용된다.
- 장애 발생 이후 다시 시작될 때는 각 파티션의 로그 세그먼트를 검사하고 불필요한 부분을 삭제하기 위해 사용된다.
- 종료될 때는 로그 세그먼트 파일을 정상적으로 닫기 위해 사용된다.

기본적으로는 로그 디렉터리당 하나의 스레드만 사용된다. 이 스레드들은 브로커의 시작과 종료 시에만 사용되므로 병행 처리를 하도록 많은 수의 스레드를 설정하는 것이 좋다.</br>
특히 많은 파티션을 갖는 브로커가 비정상적으로 종료된 후 다시 지가되어 복구될 때는 수시간의 차이가 생길수도 있다.</br>
그리고 이 매개변수에 설정하는 스레드의 수는 log.dirs에 지정된 로그 디렉터리마다 적용된다는 것에 유의한다.

* auto.create.topics.enable</br>
기본값은 true. 토픽을 자동으로 생성해 주는 유무를 설정하는 값이다.

### Topic

* num.partitions</br>
기본값은 1. 토픽의 파티션 개수는 증가만 가능하고 감소될 수는 없다.</br>
카프카 클러스터 내에서 토픽의 크기가 확장되는 방법이 파티션이다. 대부분 브로커 수와 같게 하거나, 브로커의 배수로 설정한다. 이렇게 하면 브로커마다 파티션이 고르게 분산될 수 있으며, 저장 메세지도 고르게 분산될 것이기 때문이다.</br>

    파티션 개수 산정 방법 
    
    - 단위 시간당 토픽의 데이터 처리량은?
    - 한 파티션의 데이터를 읽을 때 목표로 하는 최대 처리량은? 파티션 하나는 항상 한 컨슈머가 소비한다. 따라서 만일 처리 속도가 느린 컨슈머 파티션을 읽어서 그 데이터를 DB에 쓸 때 데이터를 쓰는 스레드마다 초당 50MB까지만 처리할 수 있다면 파티션을 소비하는 최대 처리량이 초당 50MB로 제한된다는 것을 알아두자.
    - 하나의 파티션에 데이터를 생성하는 프로듀서당 최대 처리량도 컨슈머와 같은 방법으로 산정할 수 있다. 그러나 대개 프로듀서는 컨슈머보다 훨씬 빠르게 처리되므로 처리량을 조사하지 않아도 무방하다.
    - 키를 사용해서 파티션에 메세지를 쓰는 경우에는 향후에 파티션을 추가할 때 개수 산정이 어려울 수 있다. 따라서 현재보다는 향후에 예상되는 사용 방법을 기준으로 처리량을 추산하자.
    - 브로커마다 파티션 개수와 디스크 용량 및 네트워크 처리 속도를 고려하자.
    - 파티션 개수를 너무 많이 고려하지는 말자. 왜냐하면 각 파티션은 브로커의 메모리와 그 외 다른 자원을 사용하므로 리더선정에 더 많은 시간이 소요된다.

만일 토픽의 목표처리량과 컨슈머의 예상 처리량에 관한 추정치가 있다면, 목표 처리량을 컨슈머 예상 처리량으로 나누는 방법으로 파티션 개수를 산출할 수 있다.</br>
예를 들어, 초당 1GB 로 토픽을 읽고 쓰기 원하는데 각 컨슈머가 초당 50 MB만 처리할 수 있다면 최소한 20개의 파티션이 필요하다.</br>
그러나 만일 이런 자세한 정보가 없다면 디스크에 보존하는 파티션 크기를 하루에 6GB 미만으로 제한할 것을 권한다.

* log.retention.ms</br>
기본 값은 168시간. 카프카가 얼마 동안 메세지를 보존할지 구성파일에 설정하는 값이다.</br>
주의해야할 점은, 시간별 보존은 로그 세그먼트의 마지막 수정 시간이라는 것이다. 마지막 닫히는 시점을 고려해서 설정해야 한다.

* log.retention.bytes</br>
저장된 메세지를 크기로 만기를 처리하는 방법도 있다. 예를 들어, 하나의 토픽이 8개의 파티션으로 되어 있고 이 설정값이 1GB설정되면 해당 토픽에 보존되는 메세지들의 전체 크기는 최대 8GB 가 된다. </br>
이러한 메세지 보존은 토픽이 아닌 각 파티션별로 처리된다. 따라서 이 설정값이 지정되면 그 값에 따라 토픽의 파티션 개수가 증가할 수 있다.

* log.segment.bytes</br>
로그 세그먼트 크기를 지정하는 것이다. 만일 토픽의 데이터 저장률이 낮다면 이 크기를 조정하는 것이 좋다.

* log.segment.ms</br>
위와 같은 기능을 시간으로 지정하는 것이다.

* message.max.bytes</br>
기본값은 1MB. 브로커가 쓰려는 메세지의 최대 크기이다. 이 값보다 큰 메세지를 전송하려는 프로듀서에게는 브로커가 에러를 보내고 메세지를 받지 않는다.</br>
이 값은 컨슈머의 fetch.message.max.bytes 설정값과도 맞춰 조정해야 한다. 컨슈머 설정값이 이 설정값보다 작으면 컨슈머에서 메세지 읽는 것이 실패할 수 있기 때문이다. 브로커의 replica.fetch.max.bytes 에도 같은 규칙이 적용된다.

### 프로듀서

* acks</br>
전송된 레코드를 수신하는 파티션 리플리카의 수를 제어한다. 아래와 같이 세 가지 값으로 설정한다.</br>
- 0 : 프로듀서는 브로커의 응답을 기다리지 않는다. 따라서 매우 높은 처리량이 필요할 때 사용된다.
- 1 : 리더까지만 수신하는 것을 확인한다.
- all : follower 까지 수신하는 것을 확인한다.

* buffer.memory</br>
브로커들에게 전송될 메세지의 버퍼로 사용할 메모리의 양을 이 매개변수로 설정한다. 만일 메세지들이 서버에 전달될 수 있는 것보다 더 빠른 속도로 어플리케이셔넹 전송된다면
프로듀서의 버퍼 메모리가 부족하게 될 수 있다. 그리고 추가로 호출되는 send() 메서드에서는 block.on.buffer.full 매개변수의 설정에 따라 예뢰를 일시 중단시키거나 바로 발생시킨다.

* compression.type</br>
이 매개변수를 통해 압축되어 전송한다.</br>
snappy는 cpu 부담이 적고 양호한 압축률을 제공하므로 압축 성능가 네트워크 처리량 모두가 중요할 때 사용한다. gzip은 cpu와 압축시간은 많이 사용하지만 압축률이 좋으므로 네트워크 처리량이 더 제한적일 때 사용하면 좋다.

* retries</br>
프로듀서가 서버로부터 받는 에러가 일시적일 수 있다. 따라서 이 설정값으로 메세지를 재전송하는 횟수를 제어할 수 있다. 재전송 시 기본적으로 100 밀리초동안 대기하지만, retry.backoff.ms 설정값으로 이 시간을 제어할 수 있다.</br>
이 두 설정값은 아래와 같이 고려하여 설정한다.</br>
하나의 브로커가 중단될 때 처리가 복구되는 시간(모든 파티션에 새로운 리더가 지정되는데 걸리는 시간) 을 테스트한 후에 설정한다.
또한 설정된 횟수와 대기 시간으로 재전송 중에 카프카 클러스터가 빨리 복구된다면 프로듀서는 더 이상 재전송을 하지 않을 것이다. 왜냐하면 모든 에러에서 프로듀서가 재전송을 하는 것은 아니기 때문이다.(메세지가 너무 크다는 에러를 뱉을 때)</br>
따라서 프로듀서가 자동으로 재전송해주므로 이러한 코드가 필요하지 않고, 재전송 횟수가 소진되었을 때 처리할 코드만 있으면 된다.

* batch.size</br>
같은 파티션에 쓰는 다수의 레코드가 전송될 때는 프로듀서가 그것들을 배치로 모은다. 이 매개변수는 각 배치에 사용될 메모리양을 제어한다.
그리고 해당 배치가 가득 차면 그것의 모든 메세지가 전송된다. 그렇다고 해서 배치가 가득 찰 때까지 프로듀서가 기다린다는 것은 아니다. 프로듀서는 절반만 채워진 배치와 심지어는 하나의 메세지만 있는 배치도 전송한다.
따라서 배치크기를 나타내는 이 매개변수를 큰 갑승로 설정해도 메세지 전송은 지연되지 않지만 메모리를 더 많이 사용하게 된다. 반면에, 이 값을 너무 작게 설정하면 프로듀서가 너무 자주 메세지를 전송해야 하므로 부담을 초래한다.

* linger.ms</br>
현재의 배치를 전송하기 전까지 기다리는 시간(밀리초) 를 나라낸다. 

* client.id</br>
어떤 클라이언트에서 전송된 메세지인지 식별하기위해 브로커가 사용한다. 주로 로그 메세지와 메트릭 데이터의 전송에 사용된다.

* max.in.flight.requests.per.connection</br>
서버의 응답을 받지 않고 프로듀서가 전송하는 메세지의 개수를 제어한다. 이 매개변수의 값을 크게 설정하면 메모리 사용은 증가하지만 처리량은 좋아진다.
그러나 너무 큰 값으로 설정하면 메세지의 배치 처리가 비효율적으로 되므로 오히려 처리량이 감소할 수 있다.</br>
이 값은 1로 설정하면 메세지의 전송 순서대로 브로커가 쓰게 된다. 재전송일때도 마찬가지.

* timeout.ms, request.timeout.ms, metadata.fetch.timeout.ms</br>
request.timeout.ms 는 데이터를 전송할 때, metadata.fetch.timeout.ms 는 메타데이터를 요청할 때 프로듀서가 서버의 응답을 기다리는 제한 시간을 나타낸다.</br>
만일 서버의 응답 없이 제한 시간이 경과되면 프로듀서는 재전송을 하거나 예외나 콜백을 전달하여 에러에 응답한다.</br>
timeout.ms 는 동기화된 리플리카들이 메세지를 인지하는 동안 브로커가 대기하는 시간을 제어한다. 만일 동기화된 리플리카들이 메세지를 인지하지 못한 채 이 설정값을 지나면 브로커가 에러를 반환한다.

* max.block.ms</br>
send() 메서드를 호출할 때 프로듀서의 전송 버퍼가 가득차거나 partitionsFor() 메서드로 메타데이터를 요청했지만 사용할 수 없을 때 프로듀서가 이 설정값 시간 동안 일시 중단된다.

* max.request.size</br>
프로듀서가 전송하는 쓰기요청의 크기를 제어한다. 전송될 수 있는 가장 큰 메세지의 크기와 프로듀서가 하나의 요청으로 전송할 수 있는 메세지의 최대개수 모두를 이 변수로 제한한다.</br>
예를 들어, 이 값이 1MB인 경우 전송 가능한 메세지의 최대 크기가 1MB이며, 프로듀서는 1KB 크기의 메시지를 최대 1024개까지 갖는 배치로 모아서 하나의 요청으로 전송할 수 있다.
또한 브로커에 message.max.bytes 매개변수를 서렂ㅇ하면, 생성되는 메세지의 최대 크기를 제한할 수 있다. 그러므로 max.request.size 와 message.max.bytes 갑싱 일치하도록 설정하는 것이 좋다.

* receive.buffer.bytes, send.buffer.bytes</br>
데이터를 읽고 쓸 때 소켓이 사용하는 TCP 송수신 버퍼의 크기를 나타낸다. 만일 -1로 설정하면 운영체제의 기본값이 사용된다.</br>
프로듀서와 컨슈머가 서로 다른 데이터센터의 브로커들과 통신할 때, 이 매개변수들의 값으 ㄹ증가시키는 것이 좋다. 왜냐하면 데이터센터 간 네트워크 연결의 경우 대기 시간은 길어지고 네트워크 처리량은 줄어들기 때문이다.

    메세지 순서 보장하기
    
    파티션 내부의 메세지 순서를 유지한다.
    따라서 만일 메세지가 특정 순서로 프로듀서에서 전송되면 브로커는 그 순서대로 파티션에 메세지들을 쓰며, 모든 컨슈머 또한 그 순서대로 메세지들을 읽는다.
    실제로 카프카를 사용할 때 순서가 매우 중요한 경우가 있다. 
    retries 매개변수를 0이 아닌 값으로 설정하고 max.in.flight.requests.per.connection 매개변수를 1보다 큰 값으로 설정하면,
    브로커가 첫 번째 메세지 배치를 쓰는데 실패한 후, 두 번째 배치를 쓰는 데 성공하고, 그 다음에 다시 첫 번째 배치의 쓰기를 시도하여 성공함으로써 메세지 순서가 바뀌는 경우가 생길 수 있다.</br>
    일반적으로 신뢰성이 중요한 시스템에서는 retries 매개변수를 0이 아니 ㄴ값으로 설정하지 않는다. 따라서 메세지의 순서를 유지하는 것이 중요하다면,
    in.flight.request.per.session 매개변수의 값을 1로 설정할 것을 권한다. 이 경우 한 메세지 배치의 쓰기가 다시 시도되는 동안에는 다른 메세지들이 추가로 전송되지 않기 때문이다. 그러나 이것은 프로듀서의 처리량을 심하게 제한할 수 있으므로 메세지 순서가 중요할 때만 사용하자.

### Consumer

* fetch.min.bytes </br>
레코드들을 가져올 때 브로커로부터 받기 원하는 데이터의 최소량을 이 매개변수로 지정할 수 있다. 
만일 브로커가 컨슈머로부터 레코드 요청을 받았지만 읽은 레코드들의 양이 이 값보다 작다면, 브로커는 더 많은 메세지가 모일 떄까지 기다렸다가 컨슈머에게 전송한다.
이것은 컨슈머와 브로커 모두의 작업량을 줄여준다. 왜냐면 해당 토픽들을 사용하는 일이 많이 않을 때는 상호간에 메세지를 여러 번 주고받을 필요가 없기 때문이다.
만일 읽을 데이터가 많이 않은데도 컨슈머가 CPU 를 너무 많이 사용하거나 컨슈머의 수가 많아서 브로커의 작업량을 줄이려면, 이 매개변수를 기본값보다 더 크게 설정해야 한다.

*  fetch.max.wait.ms</br>
이 값만큼 데이터가 모일 때까지 기다렸다가 컨슈머에게 전송한다. 

* max.partition.fetch.bytes</br>
기본값은 1MB. 서버가 파티션당 반환하는 최대 바이트 수를 제어한다.
컨슈머의 poll() 메서드에서 레코드를 반환할 때 그 컨슈머에게 할당된 파티션당 최대 max.partition.fetch.bytes 까지를 레코드 객체가 사용할 수 있다.
따라서 만일 한 토픽에 20개의 파티션이 있고 컨슈머는 5개라면, 각 컨슈머의 레코드에 사용 가능한 메모리는 40MB(20 x 5 x 1) 필요하다.
그러나 만일 같은 그룹의 특정 컨슈머에 문제가 생겨 처리할 수 없을 때는 나머지 컨슈머가 더 많은 파티션을 처리해야 하므로 실제로는 더 많은 메모리가 할당되어야 한다.
이 설정값은 브로커가 허용하는 가장 큰 메세지 크기(이 값은 브로커 구성 매개변수인 max.message.size 의 설정값으 결정된다) 보다 더 큰 값이어야 한다.
max.partition.fetch.bytes 를 설정할 때 중요한 것이 또 있다. 즉 컨슈머가 데이터를 처리하는 데 걸리는 시간이다.</br>
세션 타임아웃과 이에 따른 리밸런싱을 방지하는 데 충분한 시간 간격으로 컨슈머가 poll() 메서드를 호출해야 한다. 만일 한 번의 poll() 호출에서 반환하는 데이터 양이 매우 크다면, 컨슈머가 그것을 처리하는 시간이 오래 거릴ㄹ 수 있다.
따라서 세션 타임아웃을 방지하는 시간에 맞춰 폴링 루프의 다음 반복을 실행하지 못하게 될 것이다.
만일 이런 일이 생긴다면 max.partition.feth.bytes 를 더 작은 값으로 설정하거나 세션 타임아웃 시간을 늘리면 된다.

* session.timeout.ms</br>
기본값은 10초. 컨슈머가 브로커와 연결이 끊기는 시간이다. 만일 컨슈머가 GroupCoordinator 에게 하트비트를 전송하지 않으면서 이 매개변수의 값으로 설정한 시간이 경과되면, 이 컨슈머는 실행 종료된 것으로 간주되고 GroupCoordinator 는 그 컨슈머의 파티션들을 해당 그룹의 다른 컨슈머에게 할당하기 위해 해당 컨슈머 그룹의 리밸런싱을 시작시킨다.
이 매개변수는 heartbeat.interterval.ms 와 밀접한 관계가 있다. 컨슈머의 poll() 메서드에서 GroupCoordinator 에게 하트비트를 전송하는 시간 간격을 제어하는 것이 heartbeat.interval.ms 이다.
이와는 달리, 이 설정값은 컨슈머가 하트비트를 전송하지 않고 살아있을 수 있는 시간이다. 그러므로 heartbeat.interval.ms 는 session.timeout.ms 의 값보다 작아야 하며, 대개 1/3 로 설정한다.</br>
session.timeout.ms 가 기본값보다 작으면, 특정 컨슈머에 문제가 생길 때 해당 컨슈머 그룹의 리밸런싱이 더 빨리 수행될 것이다. 그러나 컨슈머들이 폴링 루프를 실행하는 데 시간이 오래 걸리거나 GC 가 수행됨으로써 원치 않는 리밸런싱이 생길 수 있다.

* auto.offset.reset</br>
기본 값은 latest. 커밋된 오프셋이 없는 파티션을 컨슈머가 읽기 시작할 때, 또는 커밋된 오프셋이 있지만 유효하지 않을 때, 컨슈머가 어떤 레코드를 읽게 할 것인지 제어하는 것이 이 변수이다.

* enable.auto.commit</br>
기본값은 true. 이 값이 true 일 경우 auto.commit.interval.ms 을 설정하여 자동으로 오프셋을 커밋하는 시간 간격을 제어할 수 있다.

* partition.assignment.strategy</br>
토픽의 파티션들이 컨슈머 그룹의 각 컨슈머에게 할당될 때, 처리하는 클래스 이름을 지정한다.
종류는 Range 와 RR 이 있다.</br>
Range 는 컨슈머들이 구독하는 모든 토픽의 파티션들을 각 컨슈머마다 연속적으로 할당한다.
예를 들어, 각각 세 개의 파티션을 갖는 T1 과 T2 토픽이 있고, C1 과 C2 컨슈머가 그 토픽들을 구독한다면, C1 은 T1 과 T2 토픽의 파티션 0 과 1을 할당받으며,
C2 는 T1 과 T2 토픽의 파티션 2를 할당받는다. 이 경우 각 토픽이 홀수 개의 파티션을 갖고 있으면서 따로 할당되므로 첫 번째 컨슈머가 두 번째 컨슈머보다 더 많은 파티션을 할당받게 된다.</br>
RR 은 구독하는 모든 토픽의 모든 파티션들을 컨슈머들에게 하나씩 번갈아 차례대로 할당한다.
만일 바로 앞의 C1 과 C2 컨슈머에게 이 전략을 적용한다면, C1 은 T1 토픽의 파티션 0과 2 및 T2 토픽을 할다압덱 된다.
그리고 C2 는 T1 토픽의 파티션 1 및 T2 토픽의 파티션 0과 2를 할당받게 된다. 모든 컨슈머가 같은 토픽들을 구독하 ㄹ때 이 전략을 사용하면 모든 컨슈머가 같은 수의 파티션을 갖게 된다.

* client.id</br>
클라이언트로부터 전송된 메세지를 식별하기 위해 브로커가 사용한다.

* max.poll.records</br>
한 번의 poll() 메서드 호출에서 반환되는 레코드의 최대 개수를 제어한다.
폴링 루프에서 애플리케이션이 처리해야 하는 데이터의 양을 제어할 때 이 매개변수가 유용하다.

* receive.buffer.bytes, send.buffer.bytes</br>
데이터를 읽거나 쓸 때 소켓이 사용하는 TCP 송수신 버퍼의 크기를 제어한다.
만일 -1로 설정하면 운영체제의 기본값이 사용된다. 프로듀서와 컨슈머가 서로 다른 데이터센터에 있는 브로커들과 통신할 때
이 매개변수들의 값을 증가시키는 것이 좋다. 그런 형태의 네트워크 연결에서느 ㄴ대기 시간이 길고 데이터 처리량이 적을 수 있기 때문이다.






Referenced from Kafka The Definitive Guide



























