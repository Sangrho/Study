### CHAPTER 19 성능 튜닝   
* 최적화 주요 영역  
    - 코드 수준의 설꼐  
    - 보관용 데이터  
    - 조인  
    - 집계  
    - 데이터 전송  
    - 애플리케이션별 속성  
    - 익스큐터 프로세스의 JVM  
    - 워커 노드  
    - 클러스터와 배포 환경 속성  
  
* 스파크 잡의 성능 튜닝 방법  
    1. 속성값을 설정하거나 런타임 환경을 변경해 *간접적* 으로 성능을 높일 수 있다.  
    2. 개별 스파크 잡, 스테이지, 태스크 성능 튜닝을 시도하거나 코드 설계를 변경해 *직접적* 으로 성능을 높일 수 있다.  
  
#### 19.1 간접적인 성능 향상 기법   
###### 19.1.1 설계 방안  
- 언어 선택 (Scala, Java, Python, R)  
- DataFrame, SQL, Dataset, RDD 선택  
    모든 언어에서 DataFrame, Dataset, SQL 의 속도는 동일하다.  
    직접 RDD 코드를 작성하는 것 보다, 컴파일 전의 단계인 그리고 훨씬 더 쉽게 사용할 수 있는 DataFrame, SQL, Dataset 을 사용하자. Spark 의 최적화 엔진이 더 나은 RDD 코드를 만들어 준다.  
  
##### 19.1.2 RDD 객체 직렬화  
Kyro 는 자바 직렬화보다 훨씬 간결하고 효율적이다.  
(Reference : https://12bme.tistory.com/567)  
  
##### 19.1.3 클러스터 설정  
- 자원 공유  
- 동적할당   
  
##### 19.1.4 스케줄링  
##### 19.1.5 보관용 데이터  
동료들이 여러 가지 분석을 수행하기 위해 동일한 데이터셋을 여러번 읽을 경우 효율적으로 읽을 수 있도록 데이터를 저장해야 한다.  
- 파일 기반 장기 데이터 저장소  
    1. 데이터를 바이너리 형태로 저장하려면 구조적 API 를 사용하는 것이 좋다.   
    2. CSV 같은 파일은 구조화되어 있는 것 처럼 보이지만 파싱 속도가 아주 느리고 예외 상황이 자주 발생한다.  
    3. 파케이는 데이터를 바이너리 파일에 컬럼 지향 방식으로 저장한다. 그리고 쿼리에서 사용하지 않는 데이터를 빠르게 건너뛸 수 있도록 몇 가지 통꼐를 함께제공한다. 또한 스파크는 파케이 데이터 소스를 내장하고 있어서 잘 호환된다.  
  
- 분할 가능한 파일 포맷과 압축  
    1. 분할 가능한 포맷을 사용하면 여러 태스크가 파일의 서로 다른 부분을 동시에 읽을 수 있다.(JSON 은 분할이 불가능 하다.)  
    2. 압축 포맷은 분할 가능 여부를 결정하는 주요 요소 중 하나다. ZPI, TAR 는 분할할 수 없으므로 병렬로 읽을 수 없다.  
    3. gzip, bzip2, lz4 를 이용해 압축된 파일이더라도 분할할 수 있다.  
  
- 테이블 파티셔닝  
    1. 자주 필터링하는 컬럼을 기준으로 파티션을 생성하는 것이 좋다.  
    2. 파티셔닝을 사용하면 쿼리에서 읽어야 하는 데이터양을 크게 줄일 수 있어 쿼리를 훨씬 빠르게 처리할 수 있다.  
- 버켓팅  
    1. 데이터를 버켓팅하면 스파크는 사용자가 조인이나 집계를 수행하는 방식에 따라 데이터를 '사전 분할' 할 수 있다.  
    2. 버켓팅을 사용하면 데이터를 한두개 파티션에 치우치지 않고 전체 파티션에 균등하게 분산시킬 수 있다.  
    3. 특정 컬럼으로 자주 조인할때는 버켓팅을 사용해 조인 컬럼의 값에 따라 데이터를 분할할 수 있다. 이렇게 하면 조인전에 발생하는 셔플을 미리 방지할 수 있으므로 데이터 접근 속도를 높일 수 있다.  
    4. 버켓팅은 물리적 데이터 분할 방법의 보완재로서 보통 파티셔닝과 함께 적용한다.  
    (Reference : https://jaceklaskowski.gitbooks.io/mastering-spark-sql/spark-sql-bucketing.html)  
- 파일 수   
    write 할 때 maxRecordsPerFile 옵션을 적용해서 HDFS 를 효율적으로 쓰자.  
- 데이터 지역성  
    네트워크를 통해 데이터 블록을 교환하지 않고 특정 데이터를 가진 노드에서 동작할 수 있도록 지정하는 것  
- 통계 수집  
    1. 테이블 수준의 통계  
        $> ANALYZE TABLE table name COMPUTE STATISTICS  
    2. 컬럼 수준의 통계  
        $> ANALYZE TABLE table)name COMPUTE STATISTICS FOR COLUMNS c1,c2,c3....  
    3. 통계는 스파크에서 빠르게 성장하는 부분이므로 통계에 기반한 다양한 최적화 기법이 계속 추가될 것이다.  
  
##### 19.1.6 셔플 설정  
##### 19.1.7 메모리 부족과 GC  
    1. GC튜닝의 목표는 두 가지이다.   
        a. 수명이 긴 캐시 데이터 셋을 Old 영역에 저장하는 것  
        b. Young 영역에서 수명이 짧은 모든 객체를 보관할 수 있도록 충분한 공간을 유지  
    2. Task 가 완료되기 전에 FUll GC 가 자주 발생한다면, 캐싱에 사용되는 메모리 양을 줄여야 한다.(Spark.memory.fraction) -> 태스크를 처리하기 위한 메모리가 부족하기 때문이다.  
    3. Major 에 비해 Minor GC 가 자주 발생한다면, Eden 에 메모리를 더 할당한다.  
    4. HDFS 데이터를 읽을 때,압축이 해제된 블록의 크기는 보통 원본 블록의 2~3배가 된다.   
  
#### 19.2 직접적인 성능 향상 기법   
##### 19.2.1 병렬화  
    1. 특정 스테이지의 처리 속도를 높이려면 가장 먼저 병렬성을 높이는 작업부터 시작해야한다.  
    2. spark.default.parallelism, spark.sqlshuffle.partitions 의 값을 클러스터 코어 수에 따라 설정한다.  
    3. 처리해야 할 데이터양이 매우 많다면, 코어 당 최소 2~3개의 태스크를 할당한다.  
##### 19.2.2 향상된 필터링    
    데이터 필터링을 통해 데이터 사이즈를 줄인다.  
##### 19.2.3 파티션 재분배와 병합         
    1. 파티션 재분배 과정은 셔플을 수반하지만, 클러스터 전체에 걸쳐 데이터가 균등하게 분배되므로 잡의 전체 실행 단계를 최적화할 수 있다.  
    2. 적은 양의 데이터를 셔플하는 것이 좋다.  
    3. 먼저 coalesce 를 통해 셔플 대신 동일 노드의 파티션을 하나로 합친다.  
    4. coalesce 보다 느린 repartition 는 부하를 분산하기 위해 네트워크로 데이터를 셔플링한다.  
    5. 파티션 재분배는 조인이나 cache 메서드 호출 시 매우 유용하다.  
    6. 파티션 재분배과정은 부하를 유발하지만, 애플리케이션의 전체적인 성능과 스파크 잡의 병렬성을 높일 수 있다. - 트레이드오프  
##### 19.2.4 UDF  
##### 19.2.5 캐싱  
    1. 단점은 캐싱할 때 직렬화,역직렬화, 저장소 자원을 소모한다.      
    2. 캐싱은 지연연산이므로, 데이터게 접근해야 캐싱이 일어난다.  
##### 19.2.6 조인  
    1. 안정성과 최적화를 위해 카테시안 조인, 전체 외부 조인의 사용을 최대한 피한다.  
    2. 조인 전에 테이블 통계를 수집하면 스파크가 조인 타입을 결정하는 데 유용하게 사용한다.  
    3. 데이터를 적절하게 버켓팅하면 조인 수행 시 거대한 양의 셔플이 발생하지 않도록 미리 방지할 수 있다.  
##### 19.2.7 집계  
##### 19.2.8 브로드캐스트 변수
